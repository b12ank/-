import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error
import matplotlib.pyplot as plt
import os
import time

start_time = time.time()
# ==========================================
# [ä¿®æ”¹ 2]åœ¨æ­¤å¤„æ§åˆ¶æ˜¯å¦å¼€å¯æ—¶é—´ç‰¹å¾
# True: åŠ å…¥å°æ—¶ã€æ˜ŸæœŸç­‰æ—¶é—´ç¼–ç  (ç†è®ºä¸Šæ•ˆæœæ›´å¥½)
# False: ä»…ä½¿ç”¨åŸå§‹5ä¸ªç‰¹å¾
ENABLE_TIME_FEATURES = False
TRAIN_OR_INFERENCE = 0  # 0:è®­ç»ƒï¼Œ1ï¼šæ¨ç†
# ==========================================

# 1.1 è¯»å–æ•°æ®å¹¶æ¸…æ´—
# [å»ºè®®] å»ºè®®ä½¿ç”¨è‹±æ–‡è·¯å¾„æˆ–ç¡®ä¿è·¯å¾„æ— ç‰¹æ®Šå­—ç¬¦ï¼Œè¿™é‡Œä¿ç•™ä½ çš„è·¯å¾„
df_raw = pd.read_csv(r"E:\pycharmproject\ç”µåŠ›äº¤æ˜“\data\æ—¥å‰_å®æ—¶_data_2024(å«ä»·å·®).csv")

# 1.2 ç¡®å®šè¾“å…¥ç‰¹å¾å’Œç›®æ ‡
INPUT = ['ç›´è°ƒè´Ÿè·', 'è”ç»œçº¿', 'é£ç”µ', 'å…‰ä¼', 'ç«ä»·ç©ºé—´', 'ä»·å·®']
OUTPUT = 'ä»·å·®'
OUTPUT_EN = 'price_diff'  # ç”¨äºä¿å­˜æ¨¡å‹å

# å¯¹åº”çš„è¾“å‡ºçš„ä¿å­˜è·¯å¾„
save_dir = os.path.join(fr"E:\pycharmproject\pytorch_test", OUTPUT + "_è®­ç»ƒæ•°æ®only2024")
os.makedirs(save_dir, exist_ok=True)

# æ¨¡å‹ä¿å­˜è·¯å¾„
model_dir = os.path.join(save_dir, "model")
os.makedirs(model_dir, exist_ok=True)

# æµ‹è¯•å›¾ä¿å­˜è·¯å¾„
picture_dir = os.path.join(save_dir, "æ¨¡å‹æµ‹è¯•å›¾")
os.makedirs(picture_dir, exist_ok=True)

# ç”¨äºå­˜å‚¨ä¸åŒç»„åˆæŒ‡æ ‡
results_list = []

# input_len_list = [1, 3, 7, 14, 30, 60]
input_len_list = [1]
# output_len_list = [1, 24]
output_len_list = [24]
if OUTPUT in INPUT:     # é¢„æµ‹ç›®æ ‡å†å²åºåˆ—ä½œä¸ºç‰¹å¾
    df1 = df_raw[INPUT]
else:                   # é¢„æµ‹ç›®æ ‡å†å²åºåˆ—ä¸ä½œä¸ºç‰¹å¾
    df1 = df_raw[INPUT + [OUTPUT]]

print("åŸå§‹æ•°æ®ç¼ºå¤±å€¼ï¼š")
print(df1.isnull().sum())

df = df1.interpolate(method='linear', limit_direction='forward').copy()  # æ’å€¼å¤„ç†ç¼ºå¤±å€¼

target_feature = df[[OUTPUT]].values  # ç›®æ ‡
# feature_cols = ['ç›´è°ƒè´Ÿè·', 'è”ç»œçº¿', 'é£ç”µ', 'å…‰ä¼', 'å®æ—¶ä»·æ ¼']
feature_cols = INPUT

for col in feature_cols:
    if df[col].dtype == object:
        df[col] = df[col].astype(str).str.replace(' ', '').astype(float)

input_features = df[feature_cols].values

print(f"å½“å‰è¾“å…¥ç‰¹å¾ç»´åº¦: {len(feature_cols)}")


# -----------------------------------------------------------------------------
# 2. æ„å»ºæ•°æ®é›† (æ”¯æŒ step å‚æ•°)
# -----------------------------------------------------------------------------
class ElectricityDataset(Dataset):
    # [ä¿®æ”¹ 4] å¢åŠ  step å‚æ•°ï¼Œæ§åˆ¶é‡‡æ ·æ­¥é•¿
    def __init__(self, data, target, seq_len=24 * 7, pred_len=24, step=1):
        self.X = []
        self.y = []
        # åˆ¶ä½œæ ·æœ¬
        # range(start, stop, step)
        for i in range(0, len(data) - seq_len - pred_len + 1, step):
            self.X.append(data[i: i + seq_len])
            self.y.append(target[i + seq_len: i + seq_len + pred_len])

        if len(self.X) > 0:
            self.X = torch.tensor(np.array(self.X), dtype=torch.float32)
            self.y = torch.tensor(np.array(self.y), dtype=torch.float32).squeeze(-1)
        else:
            self.X = torch.empty(0)
            self.y = torch.empty(0)

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]


for output_len in output_len_list:
    PRED_LEN = output_len
    for input_len in input_len_list:
        SEQ_LEN = 24 * input_len

        train_point = 7320  # å‰305å¤©7320æ¡ç”¨äºè®­ç»ƒï¼Œå61å¤©(11.1-1:00 ~ 12.31-24:00)1464æ¡ç”¨äºæµ‹è¯•
        # train_point = 8784

        X_train_raw = input_features[:train_point]
        y_train_raw = target_feature[:train_point]

        # æµ‹è¯•é›†
        X_test_raw = input_features[train_point - SEQ_LEN + PRED_LEN:]
        y_test_raw = target_feature[train_point - SEQ_LEN + PRED_LEN:]

        # åˆ’åˆ†å®Œè®­ç»ƒé›†å’Œæµ‹è¯•é›†åæ•°æ®æ ‡å‡†åŒ–
        scaler_x = MinMaxScaler(feature_range=(0, 1))
        scaler_y = MinMaxScaler(feature_range=(0, 1))

        train_data_scaled = scaler_x.fit_transform(X_train_raw)
        train_target_scaled = scaler_y.fit_transform(y_train_raw)
        test_data_scaled = scaler_x.transform(X_test_raw)
        test_target_scaled = scaler_y.transform(y_test_raw)

        # å®ä¾‹åŒ– Dataset
        # è®­ç»ƒé›†ï¼šstep=1 (å¯†é›†é‡‡æ ·ï¼Œå°½å¯èƒ½å¤šåœ°å­¦ä¹ )
        train_dataset = ElectricityDataset(train_data_scaled, train_target_scaled, seq_len=SEQ_LEN, pred_len=PRED_LEN, step=1)

        # æµ‹è¯•é›†ï¼šstep=24 (ä¸é‡å é‡‡æ ·)
        # è¿™æ ·é¢„æµ‹å‡ºæ¥çš„ç»“æœæ‹¼æ¥èµ·æ¥å°±æ˜¯ä¸€æ¡è¿ç»­çš„æ—¶é—´çº¿ï¼Œæ–¹ä¾¿ç”»å›¾å¯¹æ¯”
        test_dataset = ElectricityDataset(test_data_scaled, test_target_scaled, seq_len=SEQ_LEN, pred_len=PRED_LEN, step=output_len)

        # é˜²æ­¢æ•°æ®é‡ä¸è¶³å¯¼è‡´æŠ¥é”™
        if len(test_dataset) == 0:
            print("âš ï¸ æµ‹è¯•é›†æ•°æ®ä¸è¶³ä»¥è¿›è¡Œ step=24 çš„é‡‡æ ·ï¼Œé€€åŒ–ä¸º step=1")
            test_dataset = ElectricityDataset(X_test_raw, y_test_raw, seq_len=SEQ_LEN, pred_len=PRED_LEN, step=1)

        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)  # è®­ç»ƒå¯ä»¥ Shuffle
        test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)  # æµ‹è¯•ä¸è¦ Shuffle

        print(f"è®­ç»ƒé›†æ ·æœ¬æ•°: {len(train_dataset)}")
        print(f"æµ‹è¯•é›†æ ·æœ¬æ•°: {len(test_dataset)}")

        # -----------------------------------------------------------------------------
        # 3. å®šä¹‰ LSTM æ¨¡å‹ (è‡ªåŠ¨é€‚åº”è¾“å…¥ç»´åº¦)
        # -----------------------------------------------------------------------------
        class PricePredictor(nn.Module):
            def __init__(self, input_size, output_size):
                super(PricePredictor, self).__init__()
                # å››å±‚LSTM
                self.lstm1 = nn.LSTM(input_size, hidden_size=16, batch_first=True)
                self.lstm2 = nn.LSTM(16, hidden_size=32, batch_first=True)
                self.lstm3 = nn.LSTM(32, hidden_size=64, batch_first=True)
                self.lstm4 = nn.LSTM(64, hidden_size=128, batch_first=True)
                # ä¸‰å±‚å…¨è¿æ¥å±‚é™ç»´
                self.fc1 = nn.Linear(128, 64)
                self.fc2 = nn.Linear(64, 32)
                self.fc3 = nn.Linear(32, output_size)
                # Dropoutè®¾ç½®0.2
                self.dropout = nn.Dropout(p=0.2)

                self.relu = nn.ReLU()

            def forward(self, x):
                # å››å±‚LSTM
                x, _ = self.lstm1(x)
                x = self.dropout(x)
                x, _ = self.lstm2(x)
                x = self.dropout(x)
                x, _ = self.lstm3(x)
                x = self.dropout(x)
                x, _ = self.lstm4(x)
                x = self.dropout(x)

                # å…¨è¿æ¥å±‚é™ç»´è¾“å‡º
                x = self.fc1(x[:, -1, :])
                x = self.relu(x)
                x = self.dropout(x)
                x = self.fc2(x)
                x = self.relu(x)
                x = self.dropout(x)
                x = self.fc3(x)
                return x


        # -----------------------------------------------------------------------------
        # 4. è®­ç»ƒæµç¨‹
        # -----------------------------------------------------------------------------
        if TRAIN_OR_INFERENCE == 0:
            device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            print(f"ğŸš€ æ­£åœ¨ä½¿ç”¨è®¾å¤‡: {device}")

            # [ä¿®æ”¹ 7] input_size åŠ¨æ€ä¼ å…¥ï¼Œå–å†³äºæ˜¯å¦å¯ç”¨äº†æ—¶é—´ç‰¹å¾
            model = PricePredictor(input_size=train_data_scaled.shape[1], output_size=PRED_LEN)
            model = model.to(device)

            criterion = nn.MSELoss()
            optimizer = optim.Adam(model.parameters(), lr=0.0001)

            epochs = 100  # æ¼”ç¤ºç”¨50æ¬¡ï¼Œå®é™…å»ºè®®100+
            print("å¼€å§‹è®­ç»ƒ...")
            for epoch in range(epochs):
                model.train()
                epoch_loss = 0
                for batch_X, batch_y in train_loader:
                    batch_X = batch_X.to(device)
                    batch_y = batch_y.to(device)

                    outputs = model(batch_X)
                    loss = criterion(outputs, batch_y)

                    optimizer.zero_grad()
                    loss.backward()
                    optimizer.step()

                    epoch_loss += loss.item()

                if (epoch + 1) % 10 == 0:
                    avg_loss = epoch_loss / len(train_loader)
                    print(f"Epoch [{epoch + 1}/{epochs}], Loss: {avg_loss:.6f}")

            torch.save(model.state_dict(), os.path.join(model_dir, f"LSTM({input_len}å¤©è¾“å‡ºä¸‹{output_len}ç‚¹).pth"))
            print(f"ä¿å­˜æ¨¡å‹åˆ°:{model_dir}\LSTM({input_len}å¤©è¾“å‡ºä¸‹{output_len}ç‚¹).pth")

        # ç›´æ¥è¯»å–ä¿å­˜æ¨¡å‹å‚æ•°
        else:
            device = torch.device("cpu")  # é¢„æµ‹é€šå¸¸ä¸éœ€è¦ GPUï¼ŒCPU è¶³å¤Ÿå¿«
            model = PricePredictor(input_size=5, output_size=PRED_LEN)

            MODEL_PATH = os.path.join(model_dir, f"LSTM({input_len}å¤©è¾“å‡ºä¸‹{output_len}ç‚¹).pth")
            model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
            model.to(device)

        # -----------------------------------------------------------------------------
        # 5. [ä¿®æ”¹ 8] å…¨æµ‹è¯•é›†é¢„æµ‹ä¸è¯„ä¼°
        # -----------------------------------------------------------------------------
        plt.rcParams['font.sans-serif'] = ['SimHei']
        plt.rcParams['axes.unicode_minus'] = False

        model.eval()
        all_preds = []
        all_trues = []

        print("æ­£åœ¨å¯¹æµ‹è¯•é›†è¿›è¡Œå…¨é‡é¢„æµ‹...")
        with torch.no_grad():
            for batch_X, batch_y in test_loader:
                batch_X = batch_X.to(device)

                # é¢„æµ‹
                pred = model(batch_X)

                # æ”¶é›†æ•°æ® (è½¬å›CPU)
                all_preds.append(pred.cpu().numpy())
                all_trues.append(batch_y.numpy())

        # æ‹¼æ¥æ‰€æœ‰ Batch
        # å½¢çŠ¶ä» list of (Batch, 24) -> (Total_Samples, 24)
        np_preds = np.concatenate(all_preds, axis=0)
        np_trues = np.concatenate(all_trues, axis=0)

        # åå½’ä¸€åŒ–
        real_preds = scaler_y.inverse_transform(np_preds)
        real_trues = scaler_y.inverse_transform(np_trues)

        # æ‹‰å¹³æˆä¸€ç»´åºåˆ—ä»¥ä¾¿è®¡ç®—æŒ‡æ ‡å’Œç»˜å›¾
        flat_preds = real_preds.flatten()
        flat_trues = real_trues.flatten()


        def smape(y_true, y_pred):
            return 2.0 * np.mean(np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true))) * 100


        def sgn(x):
            if x > 0:
                return 1
            elif x == 0:
                return 0
            else:
                return -1


        def WSCR(y_actual, y_pred):  # ä»·å·®åŠ æƒå‡†ç¡®ç‡
            a = 0
            b = 0
            for i in range(len(y_actual)):
                if sgn(y_actual[i]) == sgn(y_pred[i]):
                    a += abs(y_actual[i])
                b += abs(y_actual[i])
            return a / b


        def SCR(y_actual, y_pred):  # ä»·å·®æ–¹å‘å‡†ç¡®ç‡
            a = 0
            for i in range(len(y_actual)):
                if sgn(y_actual[i]) == sgn(y_pred[i]):
                    a += 1
            return a / len(y_actual)


        # è®¡ç®—æŒ‡æ ‡
        mae = mean_absolute_error(flat_trues, flat_preds)
        rmse = np.sqrt(mean_squared_error(flat_trues, flat_preds))
        smape1 = smape(flat_trues, flat_preds)
        wscr_val = None
        scr_val = None

        print(f"\n===== è¯„ä¼°ç»“æœ (Time Features: {ENABLE_TIME_FEATURES}) =====")
        print(f"MAE (å¹³å‡ç»å¯¹è¯¯å·®): {mae:.4f}")
        print(f"RMSE (å‡æ–¹æ ¹è¯¯å·®): {rmse:.4f}")
        print(f"SMAPE: {smape1:.4f}")
        if OUTPUT == "ä»·å·®":
            wscr_val = WSCR(flat_trues, flat_preds)
            scr_val = SCR(flat_trues, flat_preds)
            print("ä»·å·®åŠ æƒå‡†ç¡®ç‡ï¼š", wscr_val)
            print("ä»·å·®æ–¹å‘å‡†ç¡®ç‡ï¼š", scr_val)

        current_result = {
            "Input_Days_len": input_len,
            "Output_Points": output_len,
            "MAE": mae,
            "RMSE": rmse,
            "SMAPE": smape1,
            "WSCR": wscr_val,  # å¦‚æœä¸æ˜¯ä»·å·®ï¼Œè¿™é‡Œæ˜¯ None
            "SCR": scr_val  # å¦‚æœä¸æ˜¯ä»·å·®ï¼Œè¿™é‡Œæ˜¯ None
        }
        results_list.append(current_result)

        # ç»˜å›¾
        plt.figure(figsize=(15, 6))
        plt.plot(flat_trues[-360:], label=f'çœŸå®{OUTPUT}', color='blue', alpha=0.7)
        plt.plot(flat_preds[-360:], label=f'é¢„æµ‹{OUTPUT}', color='red', alpha=0.7, linestyle='--')
        plt.title(f'({input_len}å¤©è¾“å‡ºä¸‹{output_len}ç‚¹){OUTPUT}é¢„æµ‹å¯¹æ¯” (MAE: {mae:.2f}, TimeFeat: {ENABLE_TIME_FEATURES})')
        plt.xlabel('æ—¶é—´ (Hours)')
        plt.ylabel(OUTPUT)
        plt.legend()
        plt.grid(True)
        plt.tight_layout()
        plt.savefig(os.path.join(picture_dir, f'LSTM_{input_len}å¤©è¾“å‡ºä¸‹{output_len}ç‚¹.png'))
        print(f"é¢„æµ‹å›¾ä¿å­˜åˆ°:{picture_dir}\LSTM_{input_len}å¤©è¾“å‡ºä¸‹{output_len}ç‚¹.png")
        try:
            plt.show()
        except Exception as e:
            print("æ˜¾ç¤ºå›¾å½¢æ—¶å‡ºç°é”™è¯¯:", e)
        # print(f"å›¾å½¢å·²ä¿å­˜ä¸º 'å®æ—¶ç”µä»·é¢„æµ‹(lstm)_{ENABLE_TIME_FEATURES}.png',è¯·æŸ¥çœ‹è¯¥æ–‡ä»¶ã€‚")

# å¾ªç¯ç»“æŸåï¼Œä¿å­˜æ‰€æœ‰ç»“æœåˆ° CSV
print("\n" + "=" * 30)
print("æ‰€æœ‰ç»„åˆè®­ç»ƒç»“æŸï¼Œæ­£åœ¨ä¿å­˜æ±‡æ€»æŒ‡æ ‡...")

results_df = pd.DataFrame(results_list)

# ä¿å­˜è·¯å¾„è®¾ç½®
save_csv_path = os.path.join(save_dir, "ä¸åŒè¾“å…¥è¾“å‡ºé•¿åº¦å¯¹æ¯”(åªç”¨å†å²æ•°æ®).csv")
# ç¡®ä¿ç›®å½•å­˜åœ¨
os.makedirs(os.path.dirname(save_csv_path), exist_ok=True)
results_df.to_csv(save_csv_path, index=False)
print(f"æŒ‡æ ‡æ±‡æ€»å·²ä¿å­˜è‡³: {save_csv_path}")

end_time = time.time()
run_time = end_time - start_time
print(f"ç¨‹åºè¿è¡Œæ—¶é—´: {run_time:.4f}ç§’")
print(f"ç¨‹åºè¿è¡Œæ—¶é—´: {run_time / 60:.4f}åˆ†")
